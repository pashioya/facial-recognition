{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BGBkRUir9f7g",
    "is_executing": true,
    "outputId": "ad00051b-6f8c-4aaa-a806-a3963ce80bdb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "\n",
    "\n",
    "base_path = \"dataset\"\n",
    "\n",
    "if not os.path.isdir(base_path):\n",
    "  os.makedirs(base_path)\n",
    "\n",
    "\n",
    "dataset_tar_path = os.path.join(base_path,\"vgg_face_dataset.tar.gz\")\n",
    "\n",
    "if not os.path.isfile(dataset_tar_path):\n",
    "  vgg_face_dataset_url = \"http://www.robots.ox.ac.uk/~vgg/data/vgg_face/vgg_face_dataset.tar.gz\"\n",
    "  \n",
    "  with request.urlopen(vgg_face_dataset_url) as r, open(os.path.join(base_path, \"vgg_face_dataset.tar.gz\"), 'wb') as f:\n",
    "    f.write(r.read())\n",
    "\n",
    "  with tarfile.open(os.path.join(base_path, \"vgg_face_dataset.tar.gz\")) as f:\n",
    "    f.extractall(os.path.join(base_path))\n",
    "\n",
    "# check if the haarcascade file exists\n",
    "if not os.path.isfile(os.path.join(base_path, \"haarcascade_frontalface_default.xml\")):\n",
    "  \n",
    "  trained_haarcascade_url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "  with request.urlopen(trained_haarcascade_url) as r, open(os.path.join(base_path, \"haarcascade_frontalface_default.xml\"), 'wb') as f:\n",
    "      f.write(r.read())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(image):\n",
    "    for img in image:\n",
    "        # plt.figure(figsize=(1, 1))\n",
    "        #   plt.subplot(1, len(images), i + 1)\n",
    "        try:\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "def get_celeb_txt_file(celeb_name):\n",
    "    return [subject for subject in sorted(os.listdir(os.path.join(base_path, \"vgg_face_dataset\", \"files\"))) if subject.startswith(celeb_name) and subject.endswith(\".txt\")]\n",
    "\n",
    "\n",
    "def get_images(subject, nb_images):\n",
    "    with open(os.path.join(base_path, \"vgg_face_dataset\", \"files\", subject), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    images_ = []\n",
    "    for line in lines:\n",
    "        url = line[line.find(\"http://\"): line.find(\".jpg\") + 4]\n",
    "        try:\n",
    "            res = request.urlopen(url)\n",
    "            img = np.asarray(bytearray(res.read()), dtype=\"uint8\")\n",
    "            img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
    "            images_.append(img)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if len(images_) == nb_images:\n",
    "            break\n",
    "\n",
    "    print(\"Number of images found: \", len(images_))\n",
    "    return images_\n",
    "\n",
    "\n",
    "def save_images_to_path(images, folder_path, person_name):\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        try:\n",
    "            # Create a unique filename for each image\n",
    "            image_path = os.path.join(folder_path, f\"{person_name}_{i}.jpg\")\n",
    "\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "            plt.savefig(image_path)\n",
    "            plt.close()  # Close the current figure to avoid memory issues\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving image {i}: {e}\")\n",
    "            \n",
    "\n",
    "def download_and_save_person_images(person_name, celeb_txt, images_folder, nb_images=20):\n",
    "    person_folder = os.path.join(images_folder, person_name)\n",
    "    \n",
    "    if not os.path.isdir(person_folder):\n",
    "        training_folder = os.path.join(person_folder, \"training\")\n",
    "        os.makedirs(training_folder, exist_ok=True)\n",
    "        \n",
    "        person_images = get_images(celeb_txt, nb_images)\n",
    "        save_images_to_path(person_images, training_folder, person_name)\n",
    "        return person_images\n",
    "    \n",
    "    # go though the training folder and return the images\n",
    "    images = []\n",
    "    for image in os.listdir(os.path.join(person_folder, \"training\")):\n",
    "        img = cv2.imread(os.path.join(person_folder, \"training\", person_name, image))\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "def create_testing_sets():\n",
    "    for person in os.listdir(images_folder):\n",
    "        person_folder = os.path.join(images_folder, person)\n",
    "        training_folder = os.path.join(person_folder, \"training\")\n",
    "        test_folder = os.path.join(person_folder, \"testing\")\n",
    "        \n",
    "        if not os.path.isdir(test_folder):\n",
    "            os.makedirs(test_folder, exist_ok=True)\n",
    "            \n",
    "            for image in random.sample(os.listdir(training_folder), nb_test_images):\n",
    "                image_path = os.path.join(training_folder, image)\n",
    "                os.rename(image_path, os.path.join(test_folder, image))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ryan Reynolds:**\n",
    "\n",
    "*Male:* Variations in facial expressions, hairstyles, however his scruffy 5 o'clock shadow is pretty much always a part of his appearance, his larger than average forehead is also a key focus point, his point upside down triangle head also made him a person of interest. \n",
    "\n",
    "**Ryan Phillippe:**\n",
    "\n",
    "*Male:* American actor with a unique and recognizable facial structure. Explore images that highlight different expressions and angles to capture his distinct appearance.\n",
    "\n",
    "**Regina Hall:**\n",
    "\n",
    "*Female:* African American actress with a dynamic and engaging presence. Emphasize diversity in hairstyles, makeup, and expressions to showcase the versatility of her appearance.\n",
    "\n",
    "**Tamara Taylor:**\n",
    "\n",
    "*Female:* Canadian actress known for her captivating looks. Highlight different aspects of her appearance, including expressions and roles that showcase her versatility.\n",
    "\n",
    "**Ryan Reynolds and Ryan Phillippe (Persons A and C):**\n",
    "\n",
    "Shared Characteristics: Both are male, have a similar facial structure, and share some genetic features\n",
    "\n",
    "**Regina Hall and Tamara Taylor (Persons B and D):**\n",
    "\n",
    "Shared Characteristics: Both are light skinned black women, with similar facial features and relatively similar hair styles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = os.path.join(\"images\") \n",
    "\n",
    "ryan_reynolds = get_celeb_txt_file(\"Ryan_Reynolds\")\n",
    "regina_hall = get_celeb_txt_file(\"Regina_Hall\")\n",
    "ryan_phillippe = get_celeb_txt_file(\"Ryan_Phillippe\")\n",
    "tamara_taylor = get_celeb_txt_file(\"Tamara_Taylor\")\n",
    "\n",
    "\n",
    "person_a_images = []\n",
    "person_b_images = []\n",
    "person_c_images = []\n",
    "person_d_images = []\n",
    "\n",
    "\n",
    "nb_images = 40\n",
    "nb_test_images = 10\n",
    "\n",
    "person_a_images = download_and_save_person_images(\"person_a\", ryan_reynolds[0], images_folder, nb_images)\n",
    "person_b_images = download_and_save_person_images(\"person_b\", regina_hall[0], images_folder, nb_images)\n",
    "person_c_images = download_and_save_person_images(\"person_c\", ryan_phillippe[0], images_folder, nb_images)\n",
    "person_d_images = download_and_save_person_images(\"person_d\", tamara_taylor[0], images_folder, nb_images)\n",
    "\n",
    "\n",
    "create_testing_sets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_images(person_a_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces(images):\n",
    "    faceCascade = cv2.CascadeClassifier(os.path.join(base_path, \"haarcascade_frontalface_default.xml\"))\n",
    "    faces = []\n",
    "    for img in images:\n",
    "        img_ = img.copy()\n",
    "        img_gray = cv2.cvtColor(img_, cv2.COLOR_BGR2GRAY)\n",
    "        faces_ = faceCascade.detectMultiScale(\n",
    "            img_gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "        faces.append(faces_)\n",
    "        \n",
    "    print(\"Found {} face(s)!\".format(len(faces)))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_file_paths(base_path):\n",
    "    training_image_paths = []\n",
    "    testing_image_paths = []\n",
    "\n",
    "    training_folder = os.path.join(base_path, \"training\")\n",
    "    testing_folder = os.path.join(base_path, \"testing\")\n",
    "    \n",
    "    for image in os.listdir(training_folder):\n",
    "        training_image_paths.append(os.path.join(training_folder, image).replace(\"\\\\\", \"/\"))\n",
    "        \n",
    "    for image in os.listdir(testing_folder):\n",
    "        testing_image_paths.append(os.path.join(testing_folder, image).replace(\"\\\\\", \"/\"))\n",
    "\n",
    "    return {\"training\": training_image_paths, \"testing\": testing_image_paths}\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "person_a_images_base_path = \"images/person_a/\"\n",
    "person_b_images_base_path = \"images/person_b/\"\n",
    "person_c_images_base_path = \"images/person_c/\"\n",
    "person_d_images_base_path = \"images/person_d/\"\n",
    "\n",
    "# def extract_features(image_paths, label):\n",
    "#     X = []\n",
    "#     y = []\n",
    "\n",
    "#     for img_path in image_paths:\n",
    "#         try:\n",
    "#             img = image.load_img(img_path, target_size=(224, 224))\n",
    "#             img_array = image.img_to_array(img)\n",
    "#             img_array = preprocess_input(img_array)\n",
    "#             features = base_model.predict(img_array.reshape(1, 224, 224, 3))\n",
    "#             X.append(features.flatten())\n",
    "#             y.append(label)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error: {e}\")\n",
    "#     return X, y\n",
    "# person_a_features = extract_features(get_image_file_paths(person_a_images_base_path, nb_images), \"person_a\")\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(person_a_features['X'], person_a_features['y'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': ['images/person_a/training/person_a_0.jpg', 'images/person_a/training/person_a_1.jpg', 'images/person_a/training/person_a_10.jpg', 'images/person_a/training/person_a_11.jpg', 'images/person_a/training/person_a_12.jpg', 'images/person_a/training/person_a_13.jpg', 'images/person_a/training/person_a_15.jpg', 'images/person_a/training/person_a_19.jpg', 'images/person_a/training/person_a_2.jpg', 'images/person_a/training/person_a_20.jpg', 'images/person_a/training/person_a_22.jpg', 'images/person_a/training/person_a_23.jpg', 'images/person_a/training/person_a_24.jpg', 'images/person_a/training/person_a_26.jpg', 'images/person_a/training/person_a_27.jpg', 'images/person_a/training/person_a_28.jpg', 'images/person_a/training/person_a_3.jpg', 'images/person_a/training/person_a_30.jpg', 'images/person_a/training/person_a_32.jpg', 'images/person_a/training/person_a_34.jpg', 'images/person_a/training/person_a_35.jpg', 'images/person_a/training/person_a_36.jpg', 'images/person_a/training/person_a_37.jpg', 'images/person_a/training/person_a_38.jpg', 'images/person_a/training/person_a_39.jpg', 'images/person_a/training/person_a_4.jpg', 'images/person_a/training/person_a_6.jpg', 'images/person_a/training/person_a_8.jpg', 'images/person_a/training/person_a_9.jpg', 'images/person_b/training/person_b_1.jpg', 'images/person_b/training/person_b_14.jpg', 'images/person_b/training/person_b_15.jpg', 'images/person_b/training/person_b_16.jpg', 'images/person_b/training/person_b_17.jpg', 'images/person_b/training/person_b_18.jpg', 'images/person_b/training/person_b_2.jpg', 'images/person_b/training/person_b_20.jpg', 'images/person_b/training/person_b_21.jpg', 'images/person_b/training/person_b_22.jpg', 'images/person_b/training/person_b_23.jpg', 'images/person_b/training/person_b_24.jpg', 'images/person_b/training/person_b_25.jpg', 'images/person_b/training/person_b_26.jpg', 'images/person_b/training/person_b_27.jpg', 'images/person_b/training/person_b_28.jpg', 'images/person_b/training/person_b_29.jpg', 'images/person_b/training/person_b_3.jpg', 'images/person_b/training/person_b_30.jpg', 'images/person_b/training/person_b_36.jpg', 'images/person_b/training/person_b_37.jpg', 'images/person_b/training/person_b_38.jpg', 'images/person_b/training/person_b_5.jpg', 'images/person_b/training/person_b_7.jpg', 'images/person_b/training/person_b_9.jpg', 'images/person_c/training/person_c_11.jpg', 'images/person_c/training/person_c_13.jpg', 'images/person_c/training/person_c_14.jpg', 'images/person_c/training/person_c_15.jpg', 'images/person_c/training/person_c_16.jpg', 'images/person_c/training/person_c_17.jpg', 'images/person_c/training/person_c_18.jpg', 'images/person_c/training/person_c_2.jpg', 'images/person_c/training/person_c_21.jpg', 'images/person_c/training/person_c_22.jpg', 'images/person_c/training/person_c_23.jpg', 'images/person_c/training/person_c_24.jpg', 'images/person_c/training/person_c_26.jpg', 'images/person_c/training/person_c_27.jpg', 'images/person_c/training/person_c_28.jpg', 'images/person_c/training/person_c_29.jpg', 'images/person_c/training/person_c_3.jpg', 'images/person_c/training/person_c_31.jpg', 'images/person_c/training/person_c_32.jpg', 'images/person_c/training/person_c_33.jpg', 'images/person_c/training/person_c_35.jpg', 'images/person_c/training/person_c_36.jpg', 'images/person_c/training/person_c_37.jpg', 'images/person_c/training/person_c_4.jpg', 'images/person_c/training/person_c_5.jpg', 'images/person_c/training/person_c_6.jpg', 'images/person_c/training/person_c_8.jpg', 'images/person_c/training/person_c_9.jpg', 'images/person_d/training/person_d_0.jpg', 'images/person_d/training/person_d_10.jpg', 'images/person_d/training/person_d_12.jpg', 'images/person_d/training/person_d_14.jpg', 'images/person_d/training/person_d_15.jpg', 'images/person_d/training/person_d_16.jpg', 'images/person_d/training/person_d_17.jpg', 'images/person_d/training/person_d_18.jpg', 'images/person_d/training/person_d_19.jpg', 'images/person_d/training/person_d_20.jpg', 'images/person_d/training/person_d_23.jpg', 'images/person_d/training/person_d_24.jpg', 'images/person_d/training/person_d_25.jpg', 'images/person_d/training/person_d_26.jpg', 'images/person_d/training/person_d_28.jpg', 'images/person_d/training/person_d_29.jpg', 'images/person_d/training/person_d_31.jpg', 'images/person_d/training/person_d_33.jpg', 'images/person_d/training/person_d_35.jpg', 'images/person_d/training/person_d_36.jpg', 'images/person_d/training/person_d_37.jpg', 'images/person_d/training/person_d_38.jpg', 'images/person_d/training/person_d_39.jpg', 'images/person_d/training/person_d_6.jpg', 'images/person_d/training/person_d_7.jpg', 'images/person_d/training/person_d_8.jpg', 'images/person_d/training/person_d_9.jpg'], 'testing': ['images/person_a/testing/person_a_16.jpg', 'images/person_a/testing/person_a_17.jpg', 'images/person_a/testing/person_a_18.jpg', 'images/person_a/testing/person_a_21.jpg', 'images/person_a/testing/person_a_25.jpg', 'images/person_a/testing/person_a_29.jpg', 'images/person_a/testing/person_a_31.jpg', 'images/person_a/testing/person_a_33.jpg', 'images/person_a/testing/person_a_5.jpg', 'images/person_a/testing/person_a_7.jpg', 'images/person_b/testing/person_b_10.jpg', 'images/person_b/testing/person_b_11.jpg', 'images/person_b/testing/person_b_12.jpg', 'images/person_b/testing/person_b_13.jpg', 'images/person_b/testing/person_b_19.jpg', 'images/person_b/testing/person_b_31.jpg', 'images/person_b/testing/person_b_33.jpg', 'images/person_b/testing/person_b_39.jpg', 'images/person_b/testing/person_b_6.jpg', 'images/person_b/testing/person_b_8.jpg', 'images/person_c/testing/person_c_0.jpg', 'images/person_c/testing/person_c_1.jpg', 'images/person_c/testing/person_c_10.jpg', 'images/person_c/testing/person_c_12.jpg', 'images/person_c/testing/person_c_19.jpg', 'images/person_c/testing/person_c_20.jpg', 'images/person_c/testing/person_c_25.jpg', 'images/person_c/testing/person_c_38.jpg', 'images/person_c/testing/person_c_39.jpg', 'images/person_c/testing/person_c_7.jpg', 'images/person_d/testing/person_d_11.jpg', 'images/person_d/testing/person_d_13.jpg', 'images/person_d/testing/person_d_2.jpg', 'images/person_d/testing/person_d_21.jpg', 'images/person_d/testing/person_d_27.jpg', 'images/person_d/testing/person_d_3.jpg', 'images/person_d/testing/person_d_30.jpg', 'images/person_d/testing/person_d_32.jpg', 'images/person_d/testing/person_d_4.jpg', 'images/person_d/testing/person_d_5.jpg']}\n",
      "Found 109 images belonging to 4 classes.\n",
      "Found 40 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "person_a_images_file_paths = get_image_file_paths(person_a_images_base_path)\n",
    "person_b_images_file_paths = get_image_file_paths(person_b_images_base_path)\n",
    "person_c_images_file_paths = get_image_file_paths(person_c_images_base_path)\n",
    "person_d_images_file_paths = get_image_file_paths(person_d_images_base_path)\n",
    "\n",
    "tmp_train_folder = os.path.join(base_path, \"tmp_train\");\n",
    "tmp_test_folder = os.path.join(base_path, \"tmp_test\");\n",
    "\n",
    "def initialize_temp_training_testing_folder(file_paths):\n",
    "    if not os.path.isdir(tmp_train_folder):\n",
    "        os.mkdir(tmp_train_folder)\n",
    "    \n",
    "    if not os.path.isdir(tmp_test_folder):\n",
    "        os.mkdir(tmp_test_folder)\n",
    "        \n",
    "    \n",
    "    # if the file oath contains train then copy to tmp_train_folder else copy to tmp_test_folder\n",
    "    for image_path in file_paths[\"training\"]:\n",
    "        person_name = image_path.split(\"/\")[1]\n",
    "        if not os.path.isdir(os.path.join(tmp_train_folder, person_name)):\n",
    "            os.mkdir(os.path.join(tmp_train_folder, person_name))\n",
    "            destination_folder = os.path.join(tmp_train_folder, person_name)\n",
    "            \n",
    "        # check if the file exists in the tmp_test_folder\n",
    "        if not os.path.isfile(os.path.join(tmp_test_folder, person_name, os.path.basename(image_path))):\n",
    "            copyfile(image_path, os.path.join(destination_folder, os.path.basename(image_path)))\n",
    "    \n",
    "    for image_path in file_paths[\"testing\"]:\n",
    "        person_name = image_path.split(\"/\")[1]\n",
    "        if not os.path.isdir(os.path.join(tmp_test_folder, person_name)):\n",
    "            os.mkdir(os.path.join(tmp_test_folder, person_name))\n",
    "            destination_folder = os.path.join(tmp_test_folder, person_name)\n",
    "            \n",
    "        # check if the file exists in the tmp_train_folder\n",
    "        if not os.path.isfile(os.path.join(tmp_train_folder, person_name, os.path.basename(image_path))):\n",
    "            copyfile(image_path, os.path.join(destination_folder, os.path.basename(image_path)))\n",
    "    \n",
    "\n",
    "\n",
    "all_image_file_paths = {\n",
    "    'training': person_a_images_file_paths['training'] + person_b_images_file_paths['training'] + person_c_images_file_paths['training'] + person_d_images_file_paths['training'],\n",
    "    'testing': person_a_images_file_paths['testing'] + person_b_images_file_paths['testing' ] + person_c_images_file_paths['testing'] + person_d_images_file_paths['testing']\n",
    "}\n",
    "\n",
    "\n",
    "initialize_temp_training_testing_folder(all_image_file_paths)\n",
    "\n",
    "\n",
    "\n",
    "trData = ImageDataGenerator()\n",
    "train_data = trData.flow_from_directory(directory=tmp_train_folder, target_size=(224, 224))\n",
    "tsData = ImageDataGenerator()\n",
    "test_data = tsData.flow_from_directory(directory=tmp_test_folder, target_size=(224, 224)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "callbacks = [checkpoint, early_stop]\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# base_model.fit_generator(train_data, steps_per_epoch=100, epochs=10, validation_data=test_data, validation_steps=10, callbacks=callbacks)\n",
    "# base_model.save(\"vgg16_1.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compile and train the model\n",
    "# model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(np.array(person_a_features[0]), np.array(person_a_features[1]), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate The Model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
